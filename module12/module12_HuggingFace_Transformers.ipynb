{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HuggingFace_Transformers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d16602f5a11426dbc4b015ee26d7ce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4586719ae78048dcac805afeac365a40",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_56499400055d48d7856b2917c8a03649",
              "IPY_MODEL_6a0eaa65905b42279b9fd3344d3812d6"
            ]
          }
        },
        "4586719ae78048dcac805afeac365a40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56499400055d48d7856b2917c8a03649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cce963a1ba8b4d178abb03fb9823d84f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 926,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 926,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5da5c3a214b5432fbccaec0a654a2421"
          }
        },
        "6a0eaa65905b42279b9fd3344d3812d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4aad2781afb349c19fc282d6b5a9a4bd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 926/926 [00:00&lt;00:00, 11.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aac347483346439e8eae9909c78e3c80"
          }
        },
        "cce963a1ba8b4d178abb03fb9823d84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5da5c3a214b5432fbccaec0a654a2421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4aad2781afb349c19fc282d6b5a9a4bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aac347483346439e8eae9909c78e3c80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42a18295444e4bf884433186819f64fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dd9ac032c7904f79a3585096ed2fac4d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1907cd230d6f4133bcd42a872af520d2",
              "IPY_MODEL_dc856405de06463b8511f44a39b15b93"
            ]
          }
        },
        "dd9ac032c7904f79a3585096ed2fac4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1907cd230d6f4133bcd42a872af520d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ea09bf135d0a42bc81a406ab876180a2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442560877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442560877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40dafeb3640348d0919628ecfa4cc1de"
          }
        },
        "dc856405de06463b8511f44a39b15b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_df91ae594e484758a97f39f248655d62",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 443M/443M [00:11&lt;00:00, 39.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_254ecc54e41d4b51a8bdc819342bf2af"
          }
        },
        "ea09bf135d0a42bc81a406ab876180a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40dafeb3640348d0919628ecfa4cc1de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df91ae594e484758a97f39f248655d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "254ecc54e41d4b51a8bdc819342bf2af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e595554139694da09b48abe07d9d3a10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6a770737ba204b47b18f5a93433cfa86",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b2bbea8ef0564c55ac70dce605ab00c1",
              "IPY_MODEL_71d6b6f98876482fad9e5c19edde45f4"
            ]
          }
        },
        "6a770737ba204b47b18f5a93433cfa86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2bbea8ef0564c55ac70dce605ab00c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c45ea17f6eef40ceb91aa449a89c2251",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 499,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 499,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a537bc7d3f1e450e8b7a6f7407dbfb0f"
          }
        },
        "71d6b6f98876482fad9e5c19edde45f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_810d33801b7a4026a86a66a52bc4bbaf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 499/499 [00:00&lt;00:00, 3.35kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd8ad596b97346f1b4d7e7a62b8beb25"
          }
        },
        "c45ea17f6eef40ceb91aa449a89c2251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a537bc7d3f1e450e8b7a6f7407dbfb0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "810d33801b7a4026a86a66a52bc4bbaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd8ad596b97346f1b4d7e7a62b8beb25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5fcf16609a0f4d2da0046795f4c867c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d7567149d50f49988d00d0c026c82555",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f62b11b798e4cf09097e844be49e325",
              "IPY_MODEL_4d850247ba544784a801d3da3b66412e"
            ]
          }
        },
        "d7567149d50f49988d00d0c026c82555": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f62b11b798e4cf09097e844be49e325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e65b0a972f9d4f61b7257661843d4f92",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 248477,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 248477,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3efe3bf0723f40b38a8db88f7d6e2924"
          }
        },
        "4d850247ba544784a801d3da3b66412e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3ac724b1904246059e007d9ae110a1a3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 248k/248k [00:00&lt;00:00, 5.44MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed5711a3522848dd9dc604f1c583b294"
          }
        },
        "e65b0a972f9d4f61b7257661843d4f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3efe3bf0723f40b38a8db88f7d6e2924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ac724b1904246059e007d9ae110a1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed5711a3522848dd9dc604f1c583b294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da6f0fe20bd0429f9b4018dbc06bf5ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5bbef20761b5426da2b591f7c2babdff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a901a1ea80874b3cbcfa0ff60478b715",
              "IPY_MODEL_fc909ba350d344b0bb0f73078b0e0cca"
            ]
          }
        },
        "5bbef20761b5426da2b591f7c2babdff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a901a1ea80874b3cbcfa0ff60478b715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bb828fb822524377813a6d5e2e5ace01",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 494860,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 494860,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07fb2c287ab8495b84886988f7fe8f46"
          }
        },
        "fc909ba350d344b0bb0f73078b0e0cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_01836492d072473e9250189a7fb06c40",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 495k/495k [00:00&lt;00:00, 1.41MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8db5fa5d897745f28dd8f9c48cb6f713"
          }
        },
        "bb828fb822524377813a6d5e2e5ace01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07fb2c287ab8495b84886988f7fe8f46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01836492d072473e9250189a7fb06c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8db5fa5d897745f28dd8f9c48cb6f713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69ee075223db4c83b596acfe2528db3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_790df181cd294bde95822e043f2b3dac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ec1a84f0f2cd4c7bb72ca6356b91b7a8",
              "IPY_MODEL_bc14c36ab2314c9f9e66e935b50183d8"
            ]
          }
        },
        "790df181cd294bde95822e043f2b3dac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec1a84f0f2cd4c7bb72ca6356b91b7a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e2982cfd2ffe496693a5b3a69eed55b6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_179c010827c44aac82ff6de804d40ab5"
          }
        },
        "bc14c36ab2314c9f9e66e935b50183d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b3189649044b4708a7b9ffa9fdc51a37",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 515B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c67296b763114f5eac569ae73a1ae4d6"
          }
        },
        "e2982cfd2ffe496693a5b3a69eed55b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "179c010827c44aac82ff6de804d40ab5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3189649044b4708a7b9ffa9fdc51a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c67296b763114f5eac569ae73a1ae4d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmZS7cc9GrSF"
      },
      "source": [
        "결과파일\n",
        "* dohyeong@c-dots.co.kr\n",
        "* jinmang2@gmail.com\n",
        "\n",
        "양식은 .ipynb\n",
        "\n",
        "추가 수행사항 \n",
        "* pre-processing 과정(모양이 어떻게 변하는지 세부)\n",
        "* model 에 태우는 과정 (중간에 어떻게 값이 변하고 어떤 layer에 값이 실제로 어떻게 들어가는지) \n",
        "* post-processing과정(logits를 NLI결과에 맞게 어떻게 변형하는지)\n",
        "\n",
        "* MARK DOWN CELL로 결과에 대한 분석정리 \n",
        "- 왜 RoBERTa를 썼는지\n",
        "- 어떤 문장은 분류를 잘하는데 맞추지 못한 문장을 살펴보니 이렇더라 기타 등등 여러분들의 분석\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8vyekbTEtdm",
        "outputId": "b016a399-a63e-45ef-8900-6a2c519966bc"
      },
      "source": [
        "!pip install -U transformers datasets scipy scikit-learn"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n",
            "Requirement already up-to-date: datasets in /usr/local/lib/python3.7/dist-packages (1.8.0)\n",
            "Requirement already up-to-date: scipy in /usr/local/lib/python3.7/dist-packages (1.7.0)\n",
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.24.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied, skipping upgrade: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied, skipping upgrade: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied, skipping upgrade: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied, skipping upgrade: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.6.1)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "411Toq5XEzpg"
      },
      "source": [
        "## 문장 분류 모델 학습\n",
        "- 필요한 라이브러리 모두 임포트 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFEF_meCEzng"
      },
      "source": [
        "import random\n",
        "import logging\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datasets\n",
        "from datasets import load_dataset, load_metric, ClassLabel, Sequence\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-HmMmVKEzlY"
      },
      "source": [
        "model_checkpoint = \"klue/roberta-base\"\n",
        "batch_size = 32\n",
        "task = \"nli\""
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKJ419W7EzjI",
        "outputId": "53caf65f-377e-4d15-af6a-8d54b19f330e"
      },
      "source": [
        "datasets = load_dataset(\"klue\", task)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset klue (/root/.cache/huggingface/datasets/klue/nli/1.0.0/55ff8f92b7a4b9842be6514ce0b4b5295b46d5e493f8bb5760da4be717018f90)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks2DaALRIOL0"
      },
      "source": [
        "훈련데이터, 검증 데이터 포함 확인가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuPpvZ7zEzgX",
        "outputId": "319fa6f5-5b03-4e1f-f45c-8c8c418558cc"
      },
      "source": [
        "datasets"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['guid', 'hypothesis', 'label', 'premise', 'source'],\n",
              "        num_rows: 24998\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['guid', 'hypothesis', 'label', 'premise', 'source'],\n",
              "        num_rows: 3000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O2mJP_BEzeI",
        "outputId": "2a5bb3a3-1fdb-4afd-a276-d6b917d5fda2"
      },
      "source": [
        "datasets[\"train\"][0]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'guid': 'klue-nli-v1_train_00000',\n",
              " 'hypothesis': '힛걸 진심 최고로 멋지다.',\n",
              " 'label': 0,\n",
              " 'premise': '힛걸 진심 최고다 그 어떤 히어로보다 멋지다',\n",
              " 'source': 'NSMC'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ax9BmVpEzbh"
      },
      "source": [
        "# 시각화 정의 \n",
        "def show_random_elements(dataset, num_examples=10):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "\n",
        "    picks = []\n",
        "    \n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "\n",
        "        # 이미 등록된 예제가 뽑힌 경우, 다시 추출\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "\n",
        "        picks.append(pick)\n",
        "\n",
        "    # 임의로 추출된 인덱스들로 구성된 데이터 프레임 선언\n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "\n",
        "    for column, typ in dataset.features.items():\n",
        "        # 라벨 클래스를 스트링으로 변환\n",
        "        if isinstance(typ, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "\n",
        "    display(HTML(df.to_html()))"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRQMRbMQInM3"
      },
      "source": [
        "KLUE NLI entailment, neutral, contradiction 세개의 라벨을 지니는 데이터셋을 확인할 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "isXW6inwIc7D",
        "outputId": "d96ae862-e3f6-4ff7-cb05-e89e1e06eb41"
      },
      "source": [
        "show_random_elements(datasets[\"train\"])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>guid</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "      <th>premise</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>klue-nli-v1_train_22174</td>\n",
              "      <td>걸어서 콜로세움에 갈 수 있습니다.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>테르미니역도 가깝도 콜로세움도 걸어갈만한 거리입니다.</td>\n",
              "      <td>airbnb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>klue-nli-v1_train_24270</td>\n",
              "      <td>운영이 중단된 시설 중 위험도가 낮고 공익적 목적이 큰 시설은 운영이 재개될 수 있다.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>현재 운영이 중단된 시설 중 위험도가 낮고 공익적 목적이 큰 시설부터 단계적으로 운영을 재개한다는 방침이다.</td>\n",
              "      <td>policy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>klue-nli-v1_train_17870</td>\n",
              "      <td>일본 영화 만의 독특함을 유일하게 따라할 수 있는 것은 한국 뿐.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>일본 영화 만이 표현할 수 있는 독특한 영상과 내러티브는 이미 세계적 수준.</td>\n",
              "      <td>NSMC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>klue-nli-v1_train_02848</td>\n",
              "      <td>단군은 사람들이 지켜보는 가운데 죽었다.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>그 뒤에 단군은 장당경 땅에 옮겨 살다가 중국 상나라 무정 8년에 이르러 죽었다.</td>\n",
              "      <td>wikipedia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>klue-nli-v1_train_19349</td>\n",
              "      <td>전개가 너무 과해서 여운이 깨졌다.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>조미료가 빠진듯한 전개가 더욱깊은 여운을 주었다.</td>\n",
              "      <td>NSMC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>klue-nli-v1_train_13825</td>\n",
              "      <td>영화 아이언맨의 팬으로서 진짜 기분 좋습니다.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>영화 아이언맨의 팬으로서 진짜 기분 더럽습니다.</td>\n",
              "      <td>NSMC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>klue-nli-v1_train_01041</td>\n",
              "      <td>가성비는 좋지 않습니다.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>가성비 시설 청결 뭐하나 빠지는게 없습니다.</td>\n",
              "      <td>airbnb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>klue-nli-v1_train_00976</td>\n",
              "      <td>한국 영화다.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>93년도 한국 코미디 최고의 영화 대박 치는데는 이유가 있다.</td>\n",
              "      <td>NSMC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>klue-nli-v1_train_03070</td>\n",
              "      <td>스웨덴에서는 성적 서비스의 구매는 불법이고 판매는 합법이다.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>그는 스웨덴처럼 성적 서비스의 판매는 합법이지만, 구매는 불법인 법안을 더 긍정적으로 생각하였다.</td>\n",
              "      <td>wikipedia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>klue-nli-v1_train_07164</td>\n",
              "      <td>독일이 승리할 것을 예견한 파울은 문어이다.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>또한, 파울은 월드컵 3, 4위전에서 우루과이를 꺾고 독일이 승리할 것을 예견하였다.</td>\n",
              "      <td>wikinews</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhzVp3V6Ii4k"
      },
      "source": [
        "# 메트릭 구현\n",
        "metric = load_metric(\"glue\", \"qnli\")"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHfGAM2HI0TA",
        "outputId": "dd3f9e50-97df-41c2-d042-9f1cd829cae7"
      },
      "source": [
        "fake_preds = np.random.randint(0, 2, size=(64,))\n",
        "fake_labels = np.random.randint(0, 2, size=(64,))\n",
        "fake_preds, fake_labels"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
              "        0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
              "        0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0]),\n",
              " array([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LSOZmAmI2_m",
        "outputId": "68ececfc-14ca-4a87-ad4b-0a818aadf605"
      },
      "source": [
        "metric.compute(predictions=fake_preds, references=fake_labels)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.5625}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlMHg_MxI877"
      },
      "source": [
        "## 토크나이저 로드 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--yrNax8I4zP",
        "outputId": "5b7b7a7d-da8b-4275-b682-dceb14fc2921"
      },
      "source": [
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/klue/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a96469ca2a238496d435a0e9e202f261119c146a0326444b6d68ae1adc35e04f.81dfabb66b2dd4b770b13875925f6126bc3d556aafe1951df64b358976fa102a\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"tokenizer_class\": \"BertTokenizer\",\n",
            "  \"transformers_version\": \"4.8.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/klue/roberta-base/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/e8441a174492958462b6b16b6db8f1e7253cd149ca779522cadd812d55091b89.d1b86bed49516351c7bb29b19d7e7be2ab53b931bcb1f9b2aacfb71f2124d25a\n",
            "loading file https://huggingface.co/klue/roberta-base/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/klue/roberta-base/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/klue/roberta-base/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/9d0c87e44b00acfbfbae931b2e4068eb6311a0c3e71e23e5400bdf57cab4bfbf.70c17d6e4d492c8f24f5bb97ab56c7f272e947112c6faf9dd846da42ba13eb23\n",
            "loading file https://huggingface.co/klue/roberta-base/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/9a9f77abeddd1bbd8de28608e78dd3604287ad91abd4796cd25ad936715b7640.1e08907f1658efd26357385b59d5a6567fc8faf443082618493ad3a2a1a45f0f\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5LN_HD9JBK1"
      },
      "source": [
        "input=tokenizer(\"힛걸 진심 최고로 멋지다.\", \"힛걸 진심 최고다 그 어떤 히어로보다 멋지다\")"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3GAllHMLaUe",
        "outputId": "b678c088-e111-4b77-e27d-d9513d87e4a9"
      },
      "source": [
        "tokenizer.all_special_ids"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 2, 3, 1, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTpVOejrLxvl",
        "outputId": "19ff8966-a018-493b-88e0-a1ac136b46ac"
      },
      "source": [
        "tokenizer.eos_token_id"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttXgBMyNLxtf",
        "outputId": "3c0188b1-57f5-4f40-8b68-609add8ac09a"
      },
      "source": [
        "tokenizer.bos_token_id"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNoTx5QlLxrU",
        "outputId": "06ef134a-50e9-4131-a499-308743547d66"
      },
      "source": [
        "tokenizer.tokenize(\"오늘 수업은 유익했을까?\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['오늘', '수업', '##은', '유익', '##했', '##을까', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb2rkPJeMAz9",
        "outputId": "ec237918-6e68-4612-bc2a-805449a8bf1a"
      },
      "source": [
        "tokenizer.encode(\"오늘 수업은 유익했을까? \")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 3822, 4851, 2073, 11576, 2371, 16809, 35, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyD9b4zNJEOL",
        "outputId": "2fcefb94-ffa6-4621-d302-98e9eda84cfc"
      },
      "source": [
        "sentence1_key, sentence2_key = (\"premise\", \"hypothesis\")\n",
        "print(f\"Sentence 1: {datasets['train'][0][sentence1_key]}\")\n",
        "print(f\"Sentence 2: {datasets['train'][0][sentence2_key]}\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence 1: 힛걸 진심 최고다 그 어떤 히어로보다 멋지다\n",
            "Sentence 2: 힛걸 진심 최고로 멋지다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjvftxaUJR3h"
      },
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[sentence1_key],\n",
        "        examples[sentence2_key],\n",
        "        truncation=True,\n",
        "        return_token_type_ids=False,\n",
        "    )"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ENL4CjcJb2v",
        "outputId": "37883dc6-f298-4d5c-c484-260dc2cf4ed0"
      },
      "source": [
        "preprocess_function(datasets[\"train\"][:5])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[0, 3, 7254, 3841, 2062, 636, 3711, 12717, 2178, 2062, 11980, 2062, 2, 3, 7254, 3841, 2200, 11980, 2062, 18, 2], [0, 3911, 2377, 2366, 1521, 3061, 4785, 1282, 2955, 3308, 3515, 2170, 22, 2532, 5675, 2, 3911, 2377, 2366, 1525, 2062, 18, 2], [0, 3911, 2377, 2366, 1521, 3061, 4785, 1282, 2955, 3308, 3515, 2170, 22, 2532, 5675, 2, 1282, 2955, 3308, 2052, 3944, 11580, 2359, 2062, 18, 2], [0, 3911, 2377, 2366, 1521, 3061, 4785, 1282, 2955, 3308, 3515, 2170, 22, 2532, 5675, 2, 3911, 2377, 2366, 5105, 2318, 831, 717, 2886, 2069, 575, 555, 2062, 18, 2], [0, 10522, 2548, 2500, 6328, 2170, 6189, 5916, 4015, 2116, 1039, 2219, 3606, 18, 2, 10522, 2548, 2500, 6328, 27135, 5916, 4015, 1642, 2015, 2259, 4258, 2219, 3606, 18, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErSpuvFSJkhx",
        "outputId": "d08c41c8-e8dc-4a9a-9b03-f37d3b06404f"
      },
      "source": [
        "encoded_datasets = datasets.map(preprocess_function, batched=True)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/klue/nli/1.0.0/55ff8f92b7a4b9842be6514ce0b4b5295b46d5e493f8bb5760da4be717018f90/cache-5e8500bb91cb9e68.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/klue/nli/1.0.0/55ff8f92b7a4b9842be6514ce0b4b5295b46d5e493f8bb5760da4be717018f90/cache-47259b99308ed811.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obNISnTuJmT6",
        "outputId": "0e7c23a5-4a93-4aae-c0b6-51814b56f41a"
      },
      "source": [
        "# klue nli의 3개의 클래스 존재하므로 , 3개의 클래스를 예측할 수 있는 sequenceclassfication구조로 모델 로드 \n",
        "num_labels = 3\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/klue/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a96469ca2a238496d435a0e9e202f261119c146a0326444b6d68ae1adc35e04f.81dfabb66b2dd4b770b13875925f6126bc3d556aafe1951df64b358976fa102a\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"tokenizer_class\": \"BertTokenizer\",\n",
            "  \"transformers_version\": \"4.8.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/klue/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/b204e0dc0a3b8fd45b35e7fcefd97c5f839b86c14aea510f1eb38fb8469e23d8.d757047baf1bb5f17f8770d3c4770b13a028de18b62aa49febbfa47a68737748\n",
            "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CFfctZ9J1TM"
      },
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiw0BKhKJ8hT",
        "outputId": "ee21abe1-db94-4b30-f50c-a28828b0be23"
      },
      "source": [
        "metric_name = \"accuracy\"\n",
        "\n",
        "args = TrainingArguments(\n",
        "    \"test-nli\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=metric_name,\n",
        ")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77QUhhZdJ-7b"
      },
      "source": [
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=encoded_datasets[\"train\"],\n",
        "    eval_dataset=encoded_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loZTP4RfRitI"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "    def __init__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data(idx)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x1hhFTqP0Q_",
        "outputId": "cf46b6d8-6455-48e9-aa67-f80c3d7f8285"
      },
      "source": [
        "train_dataloader = trainer.get_train_dataloader()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: source, guid, premise, hypothesis.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zlsoI3EURWs"
      },
      "source": [
        "trainer.get_train_dataloader\n",
        "trainer._get_eval_dataloaer\n",
        "trainer.get_test_dataloader\n",
        "trainer._prepare_inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVckdw5DP5qi"
      },
      "source": [
        "for batch in train_dataloader:\n",
        "    break"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqDcnvBbP9Dl",
        "outputId": "9f3440a1-80ac-4295-af36-89f62494e41c"
      },
      "source": [
        "batch"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " 'input_ids': tensor([[    0,  1036,  2189,  ...,     1,     1,     1],\n",
              "         [    0, 24769,  2119,  ...,     1,     1,     1],\n",
              "         [    0,  3629,  2377,  ...,     1,     1,     1],\n",
              "         ...,\n",
              "         [    0,  9528,  2073,  ...,     1,     1,     1],\n",
              "         [    0,  1111,  2181,  ...,     1,     1,     1],\n",
              "         [    0,  3625,  2236,  ...,     1,     1,     1]]),\n",
              " 'labels': tensor([2, 2, 2, 0, 2, 1, 0, 2, 2, 0, 0, 0, 2, 2, 1, 2, 2, 1, 1, 2, 1, 0, 1, 0,\n",
              "         1, 1, 1, 1, 1, 1, 0, 1])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF7Lql6rQKpI",
        "outputId": "277686d6-ebab-48aa-ffb4-4d61e3c86f0a"
      },
      "source": [
        "trainer._prepare_inputs(batch)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'),\n",
              " 'input_ids': tensor([[    0,  1036,  2189,  ...,     1,     1,     1],\n",
              "         [    0, 24769,  2119,  ...,     1,     1,     1],\n",
              "         [    0,  3629,  2377,  ...,     1,     1,     1],\n",
              "         ...,\n",
              "         [    0,  9528,  2073,  ...,     1,     1,     1],\n",
              "         [    0,  1111,  2181,  ...,     1,     1,     1],\n",
              "         [    0,  3625,  2236,  ...,     1,     1,     1]], device='cuda:0'),\n",
              " 'labels': tensor([2, 2, 2, 0, 2, 1, 0, 2, 2, 0, 0, 0, 2, 2, 1, 2, 2, 1, 1, 2, 1, 0, 1, 0,\n",
              "         1, 1, 1, 1, 1, 1, 0, 1], device='cuda:0')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nar0ANr9QdyI",
        "outputId": "b201bbb5-57b6-4490-aeb4-4e5ee435f3dc"
      },
      "source": [
        "model(**trainer._prepare_inputs(batch))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput([('loss',\n",
              "                           tensor(1.1066, device='cuda:0', grad_fn=<NllLossBackward>)),\n",
              "                          ('logits',\n",
              "                           tensor([[ 8.4469e-02,  3.2079e-03, -6.4027e-03],\n",
              "                                   [ 8.6772e-02,  1.7423e-02, -1.7413e-02],\n",
              "                                   [ 9.7222e-02,  1.0016e-02, -1.4565e-02],\n",
              "                                   [ 1.1518e-01,  7.2109e-03, -3.8598e-03],\n",
              "                                   [ 8.0482e-02,  1.7005e-02, -1.8715e-02],\n",
              "                                   [ 6.9224e-02,  1.5554e-02,  2.6161e-04],\n",
              "                                   [ 7.8064e-02,  9.0174e-03, -6.0347e-03],\n",
              "                                   [ 8.1474e-02,  1.4054e-02, -1.4120e-02],\n",
              "                                   [ 8.2775e-02,  1.0854e-03, -9.4263e-03],\n",
              "                                   [ 7.3554e-02,  3.9181e-03, -1.6987e-02],\n",
              "                                   [ 8.2310e-02,  3.9380e-02, -2.1398e-02],\n",
              "                                   [ 9.3805e-02,  1.0540e-02, -2.7066e-02],\n",
              "                                   [ 5.6285e-02,  2.0180e-02, -1.1935e-02],\n",
              "                                   [ 5.8793e-02,  1.4629e-02,  4.8291e-03],\n",
              "                                   [ 8.2330e-02,  5.4795e-03,  2.4249e-03],\n",
              "                                   [ 7.2517e-02,  2.8907e-03,  8.3973e-03],\n",
              "                                   [ 7.9482e-02,  1.8233e-02, -3.2348e-02],\n",
              "                                   [ 7.1964e-02,  3.4346e-03, -2.0125e-02],\n",
              "                                   [ 7.3013e-02,  7.1277e-03, -1.0024e-02],\n",
              "                                   [ 7.6084e-02,  2.7306e-02, -1.8518e-02],\n",
              "                                   [ 8.6564e-02,  1.3669e-02, -1.5573e-02],\n",
              "                                   [ 8.0565e-02,  1.7431e-02, -3.1261e-03],\n",
              "                                   [ 1.0784e-01,  1.3409e-02, -8.8317e-03],\n",
              "                                   [ 7.2023e-02,  1.6064e-02,  1.1197e-02],\n",
              "                                   [ 7.3505e-02, -8.9757e-03,  3.7464e-03],\n",
              "                                   [ 7.7325e-02,  1.4192e-02, -1.8250e-02],\n",
              "                                   [ 7.1304e-02,  1.8523e-02, -9.6856e-04],\n",
              "                                   [ 1.0423e-01,  2.2805e-02, -8.8979e-03],\n",
              "                                   [ 8.2694e-02, -4.6378e-03, -1.4190e-02],\n",
              "                                   [ 6.9079e-02, -6.8395e-03,  4.9298e-03],\n",
              "                                   [ 8.0513e-02,  9.3125e-03, -1.5427e-02],\n",
              "                                   [ 6.8243e-02, -3.9475e-05, -1.4010e-02]], device='cuda:0',\n",
              "                                  grad_fn=<AddmmBackward>))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA51RXDLT_Uf",
        "outputId": "0d76d9b2-8df3-4ff8-9fe5-2436e16498c8"
      },
      "source": [
        "model.roberta.embeddings"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaEmbeddings(\n",
              "  (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
              "  (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
              "  (token_type_embeddings): Embedding(1, 768)\n",
              "  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LztQ5AGXPd6u"
      },
      "source": [
        "# hyperparmeter 탐색\n",
        "#callback 생성\n",
        "# gpu 사전 setting 해준 다음 \n",
        "# optimizer 호출(Adamw)\n",
        "# linear warmup\n",
        "#=========================\n",
        "# optimizer.zero_grad()\n",
        "# train.get_train_dataloader\n",
        "# model(*batch)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QY9GOz7XKBSs",
        "outputId": "aec2a339-9eeb-4797-e407-a80cc0c6d116"
      },
      "source": [
        "\n",
        "trainer.train()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: source, guid, premise, hypothesis.\n",
            "***** Running training *****\n",
            "  Num examples = 24998\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3910\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3910' max='3910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3910/3910 29:13, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.596200</td>\n",
              "      <td>0.445513</td>\n",
              "      <td>0.834667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.283800</td>\n",
              "      <td>0.452838</td>\n",
              "      <td>0.845000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.174900</td>\n",
              "      <td>0.509905</td>\n",
              "      <td>0.861333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.104900</td>\n",
              "      <td>0.623678</td>\n",
              "      <td>0.859667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.074100</td>\n",
              "      <td>0.694698</td>\n",
              "      <td>0.862667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: source, guid, premise, hypothesis.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to test-nli/checkpoint-782\n",
            "Configuration saved in test-nli/checkpoint-782/config.json\n",
            "Model weights saved in test-nli/checkpoint-782/pytorch_model.bin\n",
            "tokenizer config file saved in test-nli/checkpoint-782/tokenizer_config.json\n",
            "Special tokens file saved in test-nli/checkpoint-782/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: source, guid, premise, hypothesis.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to test-nli/checkpoint-1564\n",
            "Configuration saved in test-nli/checkpoint-1564/config.json\n",
            "Model weights saved in test-nli/checkpoint-1564/pytorch_model.bin\n",
            "tokenizer config file saved in test-nli/checkpoint-1564/tokenizer_config.json\n",
            "Special tokens file saved in test-nli/checkpoint-1564/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: source, guid, premise, hypothesis.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to test-nli/checkpoint-2346\n",
            "Configuration saved in test-nli/checkpoint-2346/config.json\n",
            "Model weights saved in test-nli/checkpoint-2346/pytorch_model.bin\n",
            "tokenizer config file saved in test-nli/checkpoint-2346/tokenizer_config.json\n",
            "Special tokens file saved in test-nli/checkpoint-2346/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: source, guid, premise, hypothesis.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to test-nli/checkpoint-3128\n",
            "Configuration saved in test-nli/checkpoint-3128/config.json\n",
            "Model weights saved in test-nli/checkpoint-3128/pytorch_model.bin\n",
            "tokenizer config file saved in test-nli/checkpoint-3128/tokenizer_config.json\n",
            "Special tokens file saved in test-nli/checkpoint-3128/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: source, guid, premise, hypothesis.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to test-nli/checkpoint-3910\n",
            "Configuration saved in test-nli/checkpoint-3910/config.json\n",
            "Model weights saved in test-nli/checkpoint-3910/pytorch_model.bin\n",
            "tokenizer config file saved in test-nli/checkpoint-3910/tokenizer_config.json\n",
            "Special tokens file saved in test-nli/checkpoint-3910/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from test-nli/checkpoint-3910 (score: 0.8626666666666667).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3910, training_loss=0.23105953977540936, metrics={'train_runtime': 1753.8803, 'train_samples_per_second': 71.265, 'train_steps_per_second': 2.229, 'total_flos': 5710901161242060.0, 'train_loss': 0.23105953977540936, 'epoch': 5.0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "4VXg72OiKChP",
        "outputId": "58b06278-8efa-4fbd-917e-04cee5f2859c"
      },
      "source": [
        "trainer.evaluate()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: source, guid, premise, hypothesis.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='94' max='94' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [94/94 00:12]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 5.0,\n",
              " 'eval_accuracy': 0.8626666666666667,\n",
              " 'eval_loss': 0.6946976780891418,\n",
              " 'eval_runtime': 12.4046,\n",
              " 'eval_samples_per_second': 241.846,\n",
              " 'eval_steps_per_second': 7.578}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0d16602f5a11426dbc4b015ee26d7ce2",
            "4586719ae78048dcac805afeac365a40",
            "56499400055d48d7856b2917c8a03649",
            "6a0eaa65905b42279b9fd3344d3812d6",
            "cce963a1ba8b4d178abb03fb9823d84f",
            "5da5c3a214b5432fbccaec0a654a2421",
            "4aad2781afb349c19fc282d6b5a9a4bd",
            "aac347483346439e8eae9909c78e3c80",
            "42a18295444e4bf884433186819f64fb",
            "dd9ac032c7904f79a3585096ed2fac4d",
            "1907cd230d6f4133bcd42a872af520d2",
            "dc856405de06463b8511f44a39b15b93",
            "ea09bf135d0a42bc81a406ab876180a2",
            "40dafeb3640348d0919628ecfa4cc1de",
            "df91ae594e484758a97f39f248655d62",
            "254ecc54e41d4b51a8bdc819342bf2af",
            "e595554139694da09b48abe07d9d3a10",
            "6a770737ba204b47b18f5a93433cfa86",
            "b2bbea8ef0564c55ac70dce605ab00c1",
            "71d6b6f98876482fad9e5c19edde45f4",
            "c45ea17f6eef40ceb91aa449a89c2251",
            "a537bc7d3f1e450e8b7a6f7407dbfb0f",
            "810d33801b7a4026a86a66a52bc4bbaf",
            "dd8ad596b97346f1b4d7e7a62b8beb25",
            "5fcf16609a0f4d2da0046795f4c867c9",
            "d7567149d50f49988d00d0c026c82555",
            "0f62b11b798e4cf09097e844be49e325",
            "4d850247ba544784a801d3da3b66412e",
            "e65b0a972f9d4f61b7257661843d4f92",
            "3efe3bf0723f40b38a8db88f7d6e2924",
            "3ac724b1904246059e007d9ae110a1a3",
            "ed5711a3522848dd9dc604f1c583b294",
            "da6f0fe20bd0429f9b4018dbc06bf5ea",
            "5bbef20761b5426da2b591f7c2babdff",
            "a901a1ea80874b3cbcfa0ff60478b715",
            "fc909ba350d344b0bb0f73078b0e0cca",
            "bb828fb822524377813a6d5e2e5ace01",
            "07fb2c287ab8495b84886988f7fe8f46",
            "01836492d072473e9250189a7fb06c40",
            "8db5fa5d897745f28dd8f9c48cb6f713",
            "69ee075223db4c83b596acfe2528db3f",
            "790df181cd294bde95822e043f2b3dac",
            "ec1a84f0f2cd4c7bb72ca6356b91b7a8",
            "bc14c36ab2314c9f9e66e935b50183d8",
            "e2982cfd2ffe496693a5b3a69eed55b6",
            "179c010827c44aac82ff6de804d40ab5",
            "b3189649044b4708a7b9ffa9fdc51a37",
            "c67296b763114f5eac569ae73a1ae4d6"
          ]
        },
        "id": "So794ul-KIqR",
        "outputId": "bd1b3d6f-c501-46ae-d210-e54afbdb4235"
      },
      "source": [
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"Huffon/klue-roberta-base-nli\",\n",
        "    return_all_scores=True,\n",
        ")"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpazn63fs4\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d16602f5a11426dbc4b015ee26d7ce2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=926.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/1f2a1eb75d6b6ec9157f8230617554da01d84fbab7c3b1247548e56ddc3da075.639ffd48ca82a8cf821f22090cd5c77ccb77c7dded695faab148b8619bc70fc7\n",
            "creating metadata file for /root/.cache/huggingface/transformers/1f2a1eb75d6b6ec9157f8230617554da01d84fbab7c3b1247548e56ddc3da075.639ffd48ca82a8cf821f22090cd5c77ccb77c7dded695faab148b8619bc70fc7\n",
            "loading configuration file https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1f2a1eb75d6b6ec9157f8230617554da01d84fbab7c3b1247548e56ddc3da075.639ffd48ca82a8cf821f22090cd5c77ccb77c7dded695faab148b8619bc70fc7\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"klue/roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"ENTAILMENT\",\n",
            "    \"1\": \"NEUTRAL\",\n",
            "    \"2\": \"CONTRADICTION\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"CONTRADICTION\": 2,\n",
            "    \"ENTAILMENT\": 0,\n",
            "    \"NEUTRAL\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"tokenizer_class\": \"BertTokenizer\",\n",
            "  \"transformers_version\": \"4.8.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1f2a1eb75d6b6ec9157f8230617554da01d84fbab7c3b1247548e56ddc3da075.639ffd48ca82a8cf821f22090cd5c77ccb77c7dded695faab148b8619bc70fc7\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"klue/roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"ENTAILMENT\",\n",
            "    \"1\": \"NEUTRAL\",\n",
            "    \"2\": \"CONTRADICTION\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"CONTRADICTION\": 2,\n",
            "    \"ENTAILMENT\": 0,\n",
            "    \"NEUTRAL\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"tokenizer_class\": \"BertTokenizer\",\n",
            "  \"transformers_version\": \"4.8.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp8lg04sif\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42a18295444e4bf884433186819f64fb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442560877.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/94cf043d16bc422bff377e5492626b0be29ce9e4da35905a023ed18a21b8092a.283288334126ddd490b8e0d17724dc859b17b1bc304bcf6a312c8783f8833d03\n",
            "creating metadata file for /root/.cache/huggingface/transformers/94cf043d16bc422bff377e5492626b0be29ce9e4da35905a023ed18a21b8092a.283288334126ddd490b8e0d17724dc859b17b1bc304bcf6a312c8783f8833d03\n",
            "loading weights file https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/94cf043d16bc422bff377e5492626b0be29ce9e4da35905a023ed18a21b8092a.283288334126ddd490b8e0d17724dc859b17b1bc304bcf6a312c8783f8833d03\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
            "\n",
            "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at Huffon/klue-roberta-base-nli.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
            "https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpgk5nhccr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e595554139694da09b48abe07d9d3a10",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=499.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/4b753f7358ba9555903dbe4a55dceb27299b26093903185f15befbc514de0b8b.ee8a214ed94d1e1ecc5696aaa997eac2cdf003df8c56b139af4be2cec504da15\n",
            "creating metadata file for /root/.cache/huggingface/transformers/4b753f7358ba9555903dbe4a55dceb27299b26093903185f15befbc514de0b8b.ee8a214ed94d1e1ecc5696aaa997eac2cdf003df8c56b139af4be2cec504da15\n",
            "loading configuration file https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1f2a1eb75d6b6ec9157f8230617554da01d84fbab7c3b1247548e56ddc3da075.639ffd48ca82a8cf821f22090cd5c77ccb77c7dded695faab148b8619bc70fc7\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"klue/roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"ENTAILMENT\",\n",
            "    \"1\": \"NEUTRAL\",\n",
            "    \"2\": \"CONTRADICTION\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"CONTRADICTION\": 2,\n",
            "    \"ENTAILMENT\": 0,\n",
            "    \"NEUTRAL\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"tokenizer_class\": \"BertTokenizer\",\n",
            "  \"transformers_version\": \"4.8.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpu7ds777u\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fcf16609a0f4d2da0046795f4c867c9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=248477.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/7a0f92f854dcf21dadf7ea327b8a7660d43bb68d40093ebd4ba4b1529b64a232.085110015ec67fc02ad067f712a7c83aafefaf31586a3361dd800bcac635b456\n",
            "creating metadata file for /root/.cache/huggingface/transformers/7a0f92f854dcf21dadf7ea327b8a7660d43bb68d40093ebd4ba4b1529b64a232.085110015ec67fc02ad067f712a7c83aafefaf31586a3361dd800bcac635b456\n",
            "https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpncpgx78l\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da6f0fe20bd0429f9b4018dbc06bf5ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=494860.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/50f061c1a73920b08121768afb01e299e0e58c5e957f3fe4b9dd5c603bf3ffcd.74f7933572f937b11a02b2cfb4e88a024059be36c84f53241b85b1fec49e21f7\n",
            "creating metadata file for /root/.cache/huggingface/transformers/50f061c1a73920b08121768afb01e299e0e58c5e957f3fe4b9dd5c603bf3ffcd.74f7933572f937b11a02b2cfb4e88a024059be36c84f53241b85b1fec49e21f7\n",
            "https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpo01cgk1l\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69ee075223db4c83b596acfe2528db3f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/f19d8cb4ef387c04624320bbc1b3ae74420d402ecf7e14d91fdd78b30f85c4d9.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "creating metadata file for /root/.cache/huggingface/transformers/f19d8cb4ef387c04624320bbc1b3ae74420d402ecf7e14d91fdd78b30f85c4d9.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/7a0f92f854dcf21dadf7ea327b8a7660d43bb68d40093ebd4ba4b1529b64a232.085110015ec67fc02ad067f712a7c83aafefaf31586a3361dd800bcac635b456\n",
            "loading file https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/50f061c1a73920b08121768afb01e299e0e58c5e957f3fe4b9dd5c603bf3ffcd.74f7933572f937b11a02b2cfb4e88a024059be36c84f53241b85b1fec49e21f7\n",
            "loading file https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/f19d8cb4ef387c04624320bbc1b3ae74420d402ecf7e14d91fdd78b30f85c4d9.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/4b753f7358ba9555903dbe4a55dceb27299b26093903185f15befbc514de0b8b.ee8a214ed94d1e1ecc5696aaa997eac2cdf003df8c56b139af4be2cec504da15\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4rbopxzKIoO",
        "outputId": "1fb6c44a-3b5c-486d-ca42-462414a75cfd"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Huffon/klue-roberta-base-nli\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1f2a1eb75d6b6ec9157f8230617554da01d84fbab7c3b1247548e56ddc3da075.639ffd48ca82a8cf821f22090cd5c77ccb77c7dded695faab148b8619bc70fc7\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"klue/roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"ENTAILMENT\",\n",
            "    \"1\": \"NEUTRAL\",\n",
            "    \"2\": \"CONTRADICTION\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"CONTRADICTION\": 2,\n",
            "    \"ENTAILMENT\": 0,\n",
            "    \"NEUTRAL\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"tokenizer_class\": \"BertTokenizer\",\n",
            "  \"transformers_version\": \"4.8.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/7a0f92f854dcf21dadf7ea327b8a7660d43bb68d40093ebd4ba4b1529b64a232.085110015ec67fc02ad067f712a7c83aafefaf31586a3361dd800bcac635b456\n",
            "loading file https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/50f061c1a73920b08121768afb01e299e0e58c5e957f3fe4b9dd5c603bf3ffcd.74f7933572f937b11a02b2cfb4e88a024059be36c84f53241b85b1fec49e21f7\n",
            "loading file https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/f19d8cb4ef387c04624320bbc1b3ae74420d402ecf7e14d91fdd78b30f85c4d9.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/Huffon/klue-roberta-base-nli/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/4b753f7358ba9555903dbe4a55dceb27299b26093903185f15befbc514de0b8b.ee8a214ed94d1e1ecc5696aaa997eac2cdf003df8c56b139af4be2cec504da15\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "aDOiPsZQKIma",
        "outputId": "86bd30d8-a11c-4ded-cbba-bc3bcb42da76"
      },
      "source": [
        "tokenizer.sep_token"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[SEP]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykRsyEqEKIkV",
        "outputId": "32eb68db-d466-4945-ca5a-afa98199748e"
      },
      "source": [
        "classifier(f\"흡연하려면 발코니 있는 방을 선택하면 됩니다. {tokenizer.sep_token} 흡연자분들은 발코니가 있는 방이면 발코니에서 흡연이 가능합니다.\")"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'ENTAILMENT', 'score': 0.9865276217460632},\n",
              "  {'label': 'NEUTRAL', 'score': 0.01321503147482872},\n",
              "  {'label': 'CONTRADICTION', 'score': 0.00025737614487297833}]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVioDMhMKIgj",
        "outputId": "a6a9de00-09ba-4cac-9d2f-879eec2249a2"
      },
      "source": [
        "\n",
        "classifier(f\"호스트분은 영어밖에 못하십니다. {tokenizer.sep_token} 호스트분도 엄청 친절하시고 영어도 잘하십니다.\")"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'ENTAILMENT', 'score': 0.00026854671887122095},\n",
              "  {'label': 'NEUTRAL', 'score': 0.0006742391269654036},\n",
              "  {'label': 'CONTRADICTION', 'score': 0.9990572333335876}]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwgq5opcOHoJ"
      },
      "source": [
        "< 정리>\n",
        "* 왜 RoBERTa 를 썼을까? \n",
        "- 버트 모델 학습은 비싸고 하이퍼파라미터의 선택에 따라 결과값이 큰 차이가 있었다. \n",
        "다양한 실험을 통해 bert가 완벽하지 않다는 점을 확인했으며 다양한 파라미터 및 데이터 사이즈를 변화시켜 bert를 넘어서는 모델을 만들 수 있게 되었다. \n",
        "- 또한 RoBERTa 는 데이터의 양에 의해 품질이 결정된다. 최대한 많은 양의 데이터를 수집하여 비교에 적합한 데이터 양을 찾아낸다. \n",
        "- 전처리에서 마스킹을 미리하지않고 모델에 입력할 때마다 마스킹 작업을 수행한다. "
      ]
    }
  ]
}