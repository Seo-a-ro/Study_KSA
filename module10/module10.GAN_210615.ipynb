{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b63f7b8",
   "metadata": {},
   "source": [
    "## (1) import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea019406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST #Training dataset\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0) #set for testing purposes, please do not change! \n",
    "\n",
    "lr = 0.1\n",
    "device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0bd25",
   "metadata": {},
   "source": [
    "## (2) generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fee53a",
   "metadata": {},
   "source": [
    "### (2-1) generator block\n",
    "* input_dim 과 output_dim을 파라미터로 받음\n",
    "* linear layer 와 batch norm, ReLU 함수로 구성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54dd5a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3221e60",
   "metadata": {},
   "source": [
    "### generator 의 구조\n",
    "* 4개의 generator block와 FC layer, sigmoid함수로 구성\n",
    "* 28x28 해상도의 MNIST dataset 생성 \n",
    "- 입력: z_dim =10\n",
    "- 출력: im_dim =784 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b82cb2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10, im_dim=784, hidden_dim=128):\n",
    "        super(Generator,self).__init__()\n",
    "        #Build the neural network\n",
    "        self.gen = nn.Sequential(\n",
    "            gen_block(z_dim,hidden_dim),\n",
    "            gen_block(hidden_dim,hidden_dim * 2),\n",
    "            gen_block(hidden_dim * 2,hidden_dim * 4),\n",
    "            gen_block(hidden_dim * 4,hidden_dim * 8),\n",
    "            \n",
    "            nn.Linear(hidden_dim *8, im_dim),\n",
    "            nn.Sigmoid()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f933ad5",
   "metadata": {},
   "source": [
    "## (3) discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ff9453",
   "metadata": {},
   "source": [
    "### (3-1) discriminator block\n",
    "* input_dim 과 outpu_dim 을 parameter 로 받음\n",
    "* linear layer 와 ReLU 함수로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c3f1cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.LeakyReLU(0.2,inplace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554297a9",
   "metadata": {},
   "source": [
    "### (3-2)discriminator 의 구조\n",
    "* 3개의 discriminator block와 FC layer로 구성\n",
    "* 28x28 해상도의 MNIST dataset를 처리하는 discriminator \n",
    "\n",
    "- 입력: im_dim = 784\n",
    "- 출력: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38606b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, im_dim=784, hidden_dim=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            discriminator_block(im_dim, hidden_dim *4),\n",
    "            discriminator_block(hidden_dim * 4, hidden_dim *2),\n",
    "            discriminator_block(hidden_dim * 2, hidden_dim),\n",
    "            nn.Linear(hidden_dim,1)\n",
    "        )\n",
    "        \n",
    "        def forward(self, image):\n",
    "            return self.disc(image)\n",
    "\n",
    "        def get_disc(self):\n",
    "            return self.disc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f35d37",
   "metadata": {},
   "source": [
    "### (4) 기타"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbcd0b9",
   "metadata": {},
   "source": [
    "### (4-1) 노이즈 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40cf2418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(n_samples, z_dim, device='cpu'):\n",
    "    return torch.randn(n_samples, z_dim, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bbdbb2",
   "metadata": {},
   "source": [
    "### (4-2) 파라미터 셋업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d56bacdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "n_epochs = 200\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "lr = 0.00001\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b18823",
   "metadata": {},
   "source": [
    "### (4-3) 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a45aa45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    MNIST(\".\", download=True, transform=transforms.ToTensor()),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5161ea",
   "metadata": {},
   "source": [
    "## (5) loss함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05537ad0",
   "metadata": {},
   "source": [
    "### (5-1)optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9341afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(z_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(),lr=lr)\n",
    "disc = Discriminator().to(device)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650a0e89",
   "metadata": {},
   "source": [
    "### (5-2) disc loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59073b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disc_loss(gen,disc,criterion,real,num_images, z_dim, devices):\n",
    "    fake_noise = get_noise(num_images,z_dim,device=device) # z\n",
    "    fake = gen(fake_noise) #G(z)\n",
    "    disc_fake_pred = disc(fake.detach()) #D(G(z))\n",
    "    #compare fake_pred &zero\n",
    "    disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
    "    disc_loss = (disc_fake_loss + disc_real_loss) / 2\n",
    "    \n",
    "    return disc_loss\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6379035",
   "metadata": {},
   "source": [
    "### (5-3) gen loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d119afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n",
    "    fake_noise = get_noise(num_images, z_dim, device=device)\n",
    "    fake = gen(fake_noise)\n",
    "    disc_fake_pred = disc(fake.detach())\n",
    "    # compare fake_pred & ones\n",
    "    gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "\n",
    "    return gen_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806fdb42",
   "metadata": {},
   "source": [
    "## (6) image display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a66ff37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor, num_images = 25, size=(1, 28, 28)):\n",
    "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n",
    "    image_grid = make_grid(image_unfloat[:num_images], nrow = 5)\n",
    "    plt.show(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6424f",
   "metadata": {},
   "source": [
    "## (7) training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdf90789",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-1fc056f81a09>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-1fc056f81a09>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    for real, _in tqdm(dataloader):\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "cur_step =0\n",
    "mean_generator_loss =0\n",
    "mean_discriminator_loss=0\n",
    "test_generator= True\n",
    "gen_loss=False\n",
    "error=False\n",
    "\n",
    "#image_tensor = the imagesto show\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for real, _in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.view(cur_batch_size, -1).to(device)\n",
    "        \n",
    "        # update discriminator\n",
    "        disc_opt.zero_grad()\n",
    "        disc_loss = get_disc_loss(gen, disc, criterion, real, cur_batch_size, z_dim, )\n",
    "        disc_loss.backward(return_graph = True)\n",
    "        disc_opt.step()\n",
    "        \n",
    "        if test_generator:\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff59b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "module10",
   "language": "python",
   "name": "module10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
