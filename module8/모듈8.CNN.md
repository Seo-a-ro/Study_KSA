#### 딥러닝 CNN 프로젝트

#### 1. CNN적용 사례

* Deep Learning 을 이용한 지폐 시리얼 번호 인식 
* •KRW(대한민국), USD(미국), INR(인도), RUB(러시아), JPY(일본)

##### 전처리 과정 

* Ground truth(ROI값, class id )이 알맞게 되어 있는지 확인
* 딥러닝 학습을 위한 이미지 resize
![image-20210610203638294](https://user-images.githubusercontent.com/82528589/121800754-a2849980-cc6e-11eb-9f97-393531da40df.png)
* Data augmentation(RUB) 



#### Siamese network

* 두 사진을 입력으로 받아서 두 이미지를 벡터화 시킨 이후 , 두 벡터 간의 유사도를 반환하는 네트워크이다.

* Network는 data에서 직접 학습할 수 있으므로 주어진 similarity를 최적화 할 수 있는 양질의 feature를 추출해준다. 

* 샴 네트워크는 하나의 이미지를 하나의 벡터로 변환할 수 있는 weight을 가지고 있다.

* 이미지를 입력으로 받아 convolution연산을 거쳐 하나의 벡터로 이미지를 인코딩한다.

 ![image-20210610204703743](https://user-images.githubusercontent.com/82528589/121800780-b6300000-cc6e-11eb-855b-992a3228f290.png)

* 두 이미지는 공유되는 wieght로 이용하여 벡터로 인코딩 된다. 
* 두 벡터 사이의 유사도는 보통은 유클리스 공간에서 L2거리를 이용하여 정의하는 경우가 많다.
* 두 사진이 같을 경우 유사도를 1로 주고 두 사진이 다를 경우 유사도를 0으로 주어서 모델을 학습 시킨다.
* 이 때 학습에 사용하는 loss는 cross-entropy를 사용한다.
* 서로 유사한(=같은)이미지끼리는 가까운 거리를 가지고(높은 유사도) , 서로 다른 이미지 간에는 먼 거리(=낮은 유사도)를 가지도록 학습이 진행된다.
* 이와 같은 방법을 similiarity learning , metric learning이라 부른다.



### Localization

* 모델이 주어진 이미지 안의 object가 이미지 안의 어느 위치에 있는지 위치 정보를 출력 해 준다.

* 어떤 이미지를 입력했을 때 그 결과가 해당 객체를 localization(bounding box) 해준다.

* 단일 객체에 대해서만 처리한다.

  
![image-20210610205410352](https://user-images.githubusercontent.com/82528589/121800785-be883b00-cc6e-11eb-9d89-7e9264fdc2b8.png)

* 앵무새 데이터를 이용한 localization 문제 해결
  * regression 해결 문제( bounding box 예측)
![image-20210610210114340](https://user-images.githubusercontent.com/82528589/121800795-c942d000-cc6e-11eb-813e-9ebc465d9d50.png)


#### 다양한 딥러닝 아키텍처

##### Standard convolution

* 일반적으로 사용되는 convolution 이다.

Input data의 크기가 (4,4,3)에 2x2 Filter 두 개인 convolution이라고 예씨를 든다. 

Input: (4,4,3)

Filter: (2,2), 2개

Feature Map이 연산되는 과정은 다음과 같다.

![image-20210610210336050](https://user-images.githubusercontent.com/82528589/121800799-d19b0b00-cc6e-11eb-9c46-5256c4885967.png)

##### Depth-wise Convolution

* 채널마다 필터를 학습한다.
* 일반적인 convolution filter 는 입력의 모든 채널의 영향을 받게 되므로 완벽한 특정 채널만의 Spatial feature을 추출하는 것이 불가능 하다. 
* Depth-wise convolution은 각 단일 채널에 대해서만 수행되는 필터를 사용한다. 그렇기에 필터 수는 입력 채널의 수와 동일하다.

![image-20210610210336050](https://user-images.githubusercontent.com/82528589/121800820-f55e5100-cc6e-11eb-96e7-7b6f05a979a4.png)
![image-20210610210355992](https://user-images.githubusercontent.com/82528589/121800806-dc55a000-cc6e-11eb-8e08-db75cb7ff8d2.png)



##### Pointwise Convolution

* Pointwise convolution은 커널 크기(filter크기)가 1x1로 고정된 convolution layer을 말한다.
* input에 대한 Spatial Feature은 추출하지 않은 상태로, 각 채널에 대한 연산만 수행한다. 
* 따라서 output의 크기는 변하지 않고 , channel 의 수는 자유롭게 조절할 수 있다. 

* 보통 dimensional reduction을 위해 많이 쓰고, channel의 수를 줄이는 것을 의미하는데  연산량을 많이 줄일 수 있어 중요한 역할을 하게 된다. 
![image-20210610210658418](https://user-images.githubusercontent.com/82528589/121800823-fee7b900-cc6e-11eb-8bb7-d48b5d2dd7f5.png)

![image-20210610210720319](https://user-images.githubusercontent.com/82528589/121800829-03ac6d00-cc6f-11eb-94e4-030430a3a372.png)


##### MobileNetV2

* 기존의 MobileNet에서 CNN구조를 약간 더 수정하여 파라미터 수와 연산량을 더욱 줄인 네트워크이다.
* 기존의 Convolution연산을 depthwise separable convolution으로 변경한 것이다.
* depthwise separable convolution이란 depthwise convolution과 pointwise convolution의 결합이다.
![image-20210610211537603](https://user-images.githubusercontent.com/82528589/121800837-0ad37b00-cc6f-11eb-97f1-f166dab5a21b.png)

* depthwise convolution은 채널별로 분리하여 각 채널을 각각의 커널로 convolution하는 것이다.
* 이때, 입력의 채널과 출력의 채널은 항상 같다.
* pointwise convolution은 출력의 채널을 바꿀 수 있으며 , 1x1 conv 하는 것을 말한다.
![image-20210610211734462](https://user-images.githubusercontent.com/82528589/121800843-11fa8900-cc6f-11eb-9786-2df69fe648f0.png)
* 두 구조 (a),(b) block 내부는 모두 depthwise separable convolution이다. 
* (a)는 일반적으로 resnet구조에서 사용하는 residual 구조이고, block안에서는 적은 channel 수로 convolution하는 것이 특징이다. 
* (b)는 (a)와 다르게 block 안에서의 channel이 더 크고 밖에서는 축소하는 형식이다. 

* 결과적으로 연산량과 파라미터 수를 줄이기 위해 전체적으로 convolution 의 channel 수를 줄이고 , block 내부에서만 channel 수를 증가 시켰다. 
* 기존의 ReLU 대신 ReLU6를 사용하였다.
![image-20210613170442062](https://user-images.githubusercontent.com/82528589/121800850-19219700-cc6f-11eb-8e2e-e5fcd33ea576.png)

##### 전이학습 (transfer learning)

* 이전에 사용되었던 모델의 정보를 받아서 새로운 모델을 학습
* VGG, ResNet등 사전에 학습이 완료된 모델을 사용(pre-trained Model)
* 신경망의 재 학습 과정을 fine-tuning이라고 함 



* 전체 모델 새로 학습(A)
  * 데이터 셋 충분하고, 기존에 pre-trained 된 데이터 셋과 다른 특징을 가지는 경우
* convolutional base 의 일부분 고정과 나머지 계층과 분류기 학습 (B)
  * 데이터 셋 충분하고, 기존에 pre-trained 된 데이터셋과 비슷한 특징을 가지는 경우 
* 분류기만 학습(C)
  * 데이터셋만 적고, 기존에 pre-trained된 데이터셋과 비슷한 특징을 가지는 경우 
  * FC layer에 대해서만 fine-tuning을 진행 
![image-20210613170831680](https://user-images.githubusercontent.com/82528589/121800862-22126880-cc6f-11eb-8cfc-be2e2e31386f.png)

![image-20210613170844496](https://user-images.githubusercontent.com/82528589/121800866-276fb300-cc6f-11eb-8233-cb937d5dc9a2.png)



##### Grad-CAM

* gradient Class Activate Map
  * 예측 모델을 사용자가 이해하기 쉽게 표시할 수 있다.
  * 학습된 모델 결과가 타당함과 직관적으로 보이기 위해서다. (실패해 보이는 예측에 대해 이것이 왜 실패했는지 설명 가능 )
  * 예측 결과를 볼 수 있어 원인과 분석을 통하여 향후 진행 가능하다.
  * 적대적(adversarial)이미지에 대해서도 적용이 잘된다.
  * 근본적인 모델에 대해 더 신뢰할 만 하다.  
  * 데이터 셋의 bias를 동일시하여 모델 일반화를 달성한다. 

![i![image-20210613171518958](https://user-images.githubusercontent.com/82528589/121800871-2e96c100-cc6f-11eb-92a4-428cd11c9b2c.png)



##### Callback 함수

* ModelCheckpoint(모델저장)
* EarlyStopping(조기종료)
* ReduceLROnPlateau(학습률 조정)
* CSVLogger(CSV파일 저장)
